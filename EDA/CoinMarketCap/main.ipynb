{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e9041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This dataset contains information about cryptocurrency prices, market capitalization, and other metrics. \n",
    "The data is collected from CoinMarketCap (https://coinmarketcap.com/), a popular website that tracks cryptocurrency prices.\n",
    "\n",
    "This dataset can be used to:\n",
    "- Analyze the price trends of different cryptocurrencies.\n",
    "- Compare the market capitalization of different cryptocurrencies.\n",
    "- Examine the circulating supply of different cryptocurrencies.\n",
    "- Analyze the trading volume of different cryptocurrencies.\n",
    "- Study the volatility of different cryptocurrencies.\n",
    "- Compare the performance of different cryptocurrencies against each other or against a benchmark index.\n",
    "- Identify correlations between different cryptocurrency prices.\n",
    "- Use the data to build models to predict future prices or other trends.\n",
    "\n",
    "+Info: https://www.kaggle.com/datasets/harshalhonde/coinmarketcap-cryptocurrency-dataset-2023\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from utils.processing import DataLoader\n",
    "from utils.analyzer import DataAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f9000",
   "metadata": {},
   "source": [
    "---------------- LOAD DATASET -------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dc22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically detect the project's root directory\n",
    "project_root = os.path.dirname(os.path.abspath(__file__))\n",
    "sys.path.append(project_root)\n",
    "print(\"Dynamically detected root directory:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c6b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified dataset path\n",
    "df_path = os.path.join(project_root, \"dataSet\")\n",
    "print(f\"Dataset path: {df_path}\")\n",
    "df = \"currencies_data_Kaggle_2023_unique.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febfbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- LOAD AND ANALYZE DATA -------------------#\n",
    "try:\n",
    "    loader = DataLoader(df_path=df_path, df=df)\n",
    "    df = loader.load_data()\n",
    "    print(\"\\n--- Dataset successfully loaded ---\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    df = None\n",
    "except ValueError as e:\n",
    "    print(f\"Dataset value error: {e}\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdd5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with analysis if data is loaded\n",
    "if df is not None:\n",
    "    # Instantiate the analyzer\n",
    "    analyzer = DataAnalyzer(df)\n",
    "\n",
    "    # Call analyzer methods to verify functionality\n",
    "    analyzer.overview()\n",
    "    analyzer.duplicates_analysis()\n",
    "    analyzer.missing_values_analysis()  # Takes 7-10 minutes; please be patient...\n",
    "    analyzer.data_types_analysis()\n",
    "else:\n",
    "    print(\"\\n--- Could not load the dataset. Analysis aborted ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a78a3b",
   "metadata": {},
   "source": [
    "---------------- PROCESS DATA -------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0f8464",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We will handle dates, NaN values, and categorical variables\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'name.1' in df.columns:\n",
    "    df.drop(columns=['name.1'], inplace=True)\n",
    "    print(\"Column 'name.1' removed.\")\n",
    "    analyzer.data_types_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3697a6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check columns with NaN values\n",
    "nan_by_column = df.isnull().sum()\n",
    "print(nan_by_column[nan_by_column > 0])\n",
    "'''The column maxSupply contains all NaN values\n",
    "and this is because the data is unavailable, so we will fill it with 0.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e217898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)\n",
    "print(f\"Remaining NaN values: {df.isnull().sum().sum()}\")  # Confirm no NaN values remain\n",
    "analyzer.missing_values_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7430e6",
   "metadata": {},
   "source": [
    "Convert dates to datetime format and prepare for time series analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8800de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe522c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to datetime format\n",
    "df['lastUpdated'] = pd.to_datetime(df['lastUpdated'], errors='coerce')\n",
    "df['dateAdded'] = pd.to_datetime(df['dateAdded'], errors='coerce')\n",
    "analyzer.overview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99066f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporal index without dropping the column dateAdded (in case we want to work with time series later)\n",
    "df.set_index('dateAdded', inplace=True, drop=False)\n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c8b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the index (dateAdded)\n",
    "df.sort_index(inplace=True)\n",
    "print(df.index.is_monotonic_increasing)  # Should return True if sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71409afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create derived columns from 'dateAdded' to study when cryptocurrencies were added\n",
    "df['year_added'] = df.index.year\n",
    "df['month_added'] = df.index.month\n",
    "df['day_added'] = df.index.day\n",
    "df['weekday_added'] = df.index.weekday  # 0 = Monday, 6 = Sunday\n",
    "print(df[['year_added', 'month_added', 'day_added', 'weekday_added']].head())\n",
    "analyzer.overview()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data to check for more duplicates\n",
    "df['name'] = df['name'].str.strip().str.title()  # Title case for names\n",
    "df['symbol'] = df['symbol'].str.strip().str.upper()  # Uppercase for symbols\n",
    "print(df[['name', 'symbol']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74311302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates between 'name' and 'symbol'\n",
    "duplicates = df[df.duplicated(subset=['name', 'symbol'], keep=False)]\n",
    "print(duplicates)\n",
    "print(f\"Found duplicates: {duplicates.shape[0]}\")\n",
    "'''After normalizing to title case for names and uppercase for symbols,\n",
    "we found 62 duplicates for Symbol, which corresponds to USD, indicating the value in dollars\n",
    "for these cryptocurrencies as a pair value. This is not relevant, so we remove them, focusing on their symbol value.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the two remaining categorical variables: name and symbol\n",
    "'''The strategy is as follows:\n",
    "Create a dictionary mapping names to their LabelEncoder values.\n",
    "This allows us to reference this file for future visualizations or mappings.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c860a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2cf8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LabelEncoder for 'name'\n",
    "le = LabelEncoder()\n",
    "df['name_encoded'] = le.fit_transform(df['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66de9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping 'name' -> 'name_encoded'\n",
    "name_to_encoded = dict(zip(df['name'], df['name_encoded']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the result\n",
    "print(\"First encoded values:\")\n",
    "print(df[['name', 'name_encoded']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a CSV file\n",
    "mapping_df = pd.DataFrame(list(name_to_encoded.items()), columns=['name', 'name_encoded'])\n",
    "mapping_df.to_csv('EDA/CoinMarketCap/dataSet/name_encoded_mapping.csv', index=False)\n",
    "print(\"Mapping dictionary created and saved as 'name_encoded_mapping.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31584e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns 'name' and 'symbol'\n",
    "df = df.drop(columns=['name', 'symbol'])\n",
    "print(\"Remaining columns after removing 'name' and 'symbol':\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e727f2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Save the cleaned dataset ready for further analysis and/or training\n",
    "df.to_csv('EDA/CoinMarketCap/dataSet/currencies_data_ready.csv', index=False)\n",
    "print(\"Dataset ready and saved as 'currencies_data_ready.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326cf3f9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "-------> VISUALIZAMOS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11b5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to remove rows with extreme outliers or missing values\n",
    "filtered_df = df[(df['maxSupply'] > 0) & (df['price'] > 0)].copy()\n",
    "filtered_df['maxSupply_jittered'] = filtered_df['maxSupply'] + np.random.uniform(-1e16, 1e16, size=len(filtered_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b7728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'dateAdded' to datetime (if not already done)\n",
    "filtered_df['dateAdded'] = pd.to_datetime(filtered_df['dateAdded'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6507e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the plot\n",
    "plt.figure(figsize=(14, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c687ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with jittered maxSupply\n",
    "sns.scatterplot(\n",
    "    data=filtered_df,\n",
    "    x='dateAdded',\n",
    "    y='maxSupply_jittered',\n",
    "    hue='price',\n",
    "    size='price',\n",
    "    sizes=(20, 200),\n",
    "    palette=sns.color_palette(['#4c72b0', '#55a868', '#c44e52']),  # Changed to a professional \"Blues\" palette\n",
    "    alpha=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89651fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhance the plot with titles and labels\n",
    "plt.title('Cryptocurrency Max Supply Over Time, Colored by Price (With Jitter)', fontsize=16, pad=20)\n",
    "plt.xlabel('Date Added', fontsize=12)\n",
    "plt.ylabel('Max Supply (Jittered)', fontsize=12)\n",
    "plt.legend(title='Price ($)', fontsize=10, loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6869d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
